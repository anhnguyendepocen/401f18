%\documentclass[handout]{beamer}
\documentclass{beamer}

% \newcommand\answer[2]{\textcolor{blue}{#2}} % to show answers
 \newcommand\answer[2]{#1} % to show blank space
<<R_answer,echo=F,purl=F>>=
# ANS = TRUE
 ANS=FALSE
@

\input{../header.tex}
\newcommand\CHAPTER{4}
%\newcommand\LSi{\mathrm{(LS1)}}
%\newcommand\LSii{\mathrm{(LS2)}}
%\newcounter{tXX}
%\newcounter{tXy}
%\newcounter{matrixLSi}

\begin{document}

% knitr set up
<<knitr_opts,echo=F,purl=F>>=
library(knitr)
opts_chunk$set(
#  cache=FALSE,
  cache=TRUE,
  eval=TRUE,
  include=TRUE,
  echo=TRUE,
  purl=TRUE,
  cache.path=paste0("tmp/cache"),
  dev='png',
  dev.args=list(bg='transparent'),
  dpi=300,
  error=FALSE, 
  fig.pos="h!",
  fig.align='center',
  fig.height=4,fig.width=6.83,
  fig.lp="fig:",
  fig.path=paste0("tmp/figure"),
  fig.show='asis',
  highlight=TRUE,
  message=FALSE,
  progress=TRUE,
  prompt=FALSE,
#  results='asis',
  results="markup",
  size='small',
  strip.white=TRUE,
  tidy=FALSE,
  warning=FALSE
#  comment=NA # to remove ## on output
)

options(width = 60) # number of characters in R output before wrapping
@

% other set up
<<setup,echo=F,results=F,cache=F>>=
library(broman) # used for myround 
@


\begin{frame}[fragile]
\frametitle{Chapter \CHAPTER. Probability models}

\vspace{-1mm}

\begin{myitemize}
\item A \myemph{probability model} is an assignment of probabilities to possible outcomes. 

\item We don't observe these probabilities. We observe a particular dataset.

\item If we treat the dataset as an outcome of a probability model, we can answer questions such as,

\vspace{3mm}

``{\it If there really is no association between unemployment and life expectancy, what is the probability we would see an estimated linear model coefficient as large as the one we actually observed, due to random fluctuations in both quantities?}''

\vspace{3mm}

\item Here, we are most interested in developing a probability model for the linear model.

\item First, we need some basic tools for probability models: random variables, the normal distribution, mean, variance and standard deviation.

\end{myitemize}
\end{frame}

%\end{document}

\begin{frame}[fragile]
\frametitle{Random variables and events}

\begin{myitemize}
\item A \myemph{random variable} \m{X} is a random number with probabilities assigned to outcomes.

Example:  Let \m{X} be a roll of a fair die. A natural probability model is to assign probability of \m{1/6} to each of the possible outcomes \m{1,2,3,4,5,6}.

\item An \myemph{event} is a set of possible outcomes.

Example:  For a die, \m{E=\{X\ge 4\}=\{4,5,6\}} is the event that the die shows \m{4} or more.

\item We can assign probabilities to events just like to outcomes.

Example: For a die, \m{\prob(E)=\prob(X\ge 4)= 3/6 = 1/2}.

\end{myitemize}
\myquestion. If an experiment can be repeated many times (like rolling a die) how can you check whether the probability model is correct?

\answer{\vspace{20mm}}{For a correct probability model, the probability of an event should match the long run proportion of the time that the event happens in many repetitions. This is the \myemph{law of large numbers}}. 

\end{frame}

%\end{document}

\begin{frame}[fragile]
\frametitle{Notation for combining events}
\begin{myitemize}
\item \m{\{\mbox{$E$ or $F$}\}} is the event that either \m{E} or \m{F} or both happens.
\item Since \m{E} and \m{F} are sets, we can write this as a union,
 \m{\{\mbox{$E$ or $F$}\}= E\cup F}
\item \m{\{\mbox{$E$ and $F$}\}} is the event that both \m{E} and \m{F} happen.
\item We can write this as an intersection,
\mydisplaymath{
  \{\mbox{$E$ and $F$}\}=E\cap F
}
\item Usually, we prefer ``and/or'' to  ``intersection/union''. 
\end{myitemize}
\myquestion. When does this formal use of ``and/or'' agree with usual English usage? When does it disagree?

\answer{\vspace{20mm}}

\end{frame}

%\end{document}

\begin{frame}[fragile]
\frametitle{The basic rules of probability}

\vspace{-1.5mm}

\begin{enumerate}
\item Probabilities are numbers between 0 (impossible) and 1 (certain).

\item  Let \m{\Sspace} be the set of all possible outcomes. Then, \m{\prob(\Sspace)=1}.

Example: For a die, \m{\prob(X\in\{1,2,3,4,5,6\})=1}.

\item Events \m{E} and \m{F} are called \myemph{mutually exclusive} if they cannot happen at the same time. In other words, their intersection is the empty set. In this case,

\vspace{-4mm}

\mydisplaymath{
\prob(\mbox{$E$ or $F$})=\prob(E)+\prob(F).
}

%\end{myitemize}
\end{enumerate}

\myquestion. You roll a red die and a blue die. Let \m{E=\{\mbox{red die shows 1}\}}, \m{F=\{\mbox{blue die shows 1}\}}, \m{G=\{\mbox{red die shows 6}\}}. (a) Are \m{E} and \m{F} mutually exclusive? (b) How about \m{E} and \m{G}? (c) How about \m{F} and \m{G}?

\answer{\vspace{25mm}}{TODO}

\end{frame}


%\end{document}

\begin{frame}[fragile]
\frametitle{Discrete random variables}
\begin{myitemize}
\item A \myemph{discrete random variable} is one where we can list all possible outcomes. Let's call them \m{x_1,x_2,\dots}. 

\item A discrete random variable is specified by probability that the random variable takes each possible outcome,
\mydisplaymath{
  p_i = \prob[X=x_i], \mbox{for $i = 1,2,3,\dots$}
}

\item It can be helpful to plot a graph of \m{p_i} against \m{x_i}.
\item This graph is called the \myemph{probability mass function}.
\end{myitemize}
\myquestion. Sketch the probability mass function for a fair die.

\answer{\vspace{40mm}}

\end{frame}

%\end{document}

\begin{frame}[fragile]
\frametitle{Simulating the law of large numbers}
\begin{myitemize}
\item The ``law of large numbers'' says that the proportion of each outcome \m{i} in a large number of draws of a discrete random variable approaches \m{p_i}.

\item We can test this by simulation, using the \code{replicate()} command.
\end{myitemize}

\WorkedExample. In R, a random draw with replacement from \m{\{1,2,3,4,5,6\}} can be obtained by
\code{sample(1:6,size=1)}
This is equivalent to one roll of a fair die.

%\vspace{-5mm}

<<hist100,echo=T,eval=F,purl=TRUE>>=
hist(replicate(n=100,sample(1:6,size=1) ),
  main="",prob=TRUE,breaks=0.5:6.5,xlab="n=100",ylim=c(0,0.21))
@

<<hist10000,eval=F,echo=F,purl=TRUE>>=
hist(replicate(sample(1:6,size=1),n=10000),
  main="", prob=TRUE, breaks=0.5:6.5, xlab="n=10000",ylim=c(0,0.21))
@

\vspace{-15mm}

\begin{columns}[T] 
\begin{column}{0.45\textwidth}
<<hist100eval,out.width="60mm",fig.width=3.5,fig.height=3,echo=F,purl=F>>=
set.seed(23)
<<hist100>> 
@
\end{column}


\begin{column}{0.45\textwidth}

<<hist10000eval,out.width="60mm",fig.width=3.5,fig.height=3,echo=F,purl=F>>=
set.seed(196)
<<hist10000>> 
@
\end{column}
\end{columns}

%hist(replicate(sample(1:6),n=10),
%histogram(sample(1:6,n=100))
%histogram(sample(1:6,n=1000))
%histogram(sample(1:6,n=10000))

\end{frame}


\end{document}

A continuous random variable is one which can take possible values in an interval of the real numbers.

An important example of this is the normal distribution. Random draws from the normal distribution are obtained by rnorm() in R and we can use multiple \myemph{simulations} of the random  draws to learn about the distribution.

histogram(rnorm(n=1000,mean=20,sd=5))

Mathematically, we say this is a histogram of 1000 random variables drawn from the Normal(20,5) distribution.

The mean is a measure of center, which we'll define soon, and sd (standard deviation) is a measure of spread.

We see that the points are centered around the mean, 20, and most of them fall within two standard deviations(+/- 10) of the mean.

For a continuous random variable, the probability that the random variable falls in an interval is given by the area under its \myemph{probability density} curve.

Let X be a \myemph{standard normal random variable}, with mean=0 and sd=1. We write X\sim \normal[0,1]. The probability density function for X is usually called phi(x) and has the mathematical formula

phi(x) = \frac{1}{\sqrt{2\pi}}e^{-x^2/2}

\myquestion. Suppose X\sim Normal[0,1]. Write \prob[-2\le X\le 2] as an integral and use R to evaluate this probability.

solution. [DRAW SHADED PLOT OF NORMAL CURVE HERE]

We want the shaded area. It is formally given by

\mydisplaymath{
shaded area = \int_{-2}^2 \phi(x) dx = \int_{-2}^2 \frac{1}{\sqrt{2\pi}}e^{-x^2/2} \, dx
}

This integral has no nice solution, so we ask R to evaluate it numerically, using the R function pnorm.

pnorm(x,mean=0,sd=1) computes the left tail of the standard normal distribution up to x

Mathematically, pnorm(x,0,1)=\prob(X\le x) when X\sim \normal(0,1)

Visually, pnorm(x,0,1) is the following shaded area

[DRAW SHADED PLOT OF NORMAL CURVE HERE]

pnorm(x,0,1) is called the standard normal cumulative distribution function, and it is usually written as Phi(x), so mathematically

\Phi(x)=\int_{-\infty}^x \phi(z)\, dz.

R knows many other probability distributions. For example, try hist(rexp(1000)) or hist(runif(1000)), or
?[WHAT TO SEARCH FOR R HELP?]
. The normal distribution is by far the most important. Let's find out why. 

The central limit theorem

The sum of many random variables follows the normal distribution. This is called the CLT.

Example: let's look at histograms of 1000 replications of the sum of n dice, and see what happens as n increases.




\myquestion. Would you expect the heights of adult males (or adult females) to follow a normal distribution? You can give arguments for and against

\myquestion. Would you expect the height of all adults to follow a normal distribution? Explain.

The normal distribution is often used to model \myemph{measurement error}, when we suppose there is some true underlying quantity on which we make an imperfect measurement. 

\myquestion. Would you expect the measurement of life expectancy at birth to have normally distributed measurement error?

\myquestion. Consider the mice weight data for HW1 with mice randomized to two treatments: a high fat diet and a usual lab diet. (a) Would you expect the weights of mice in each treatment group to follow a normal distribution? (b) If the experiment were replicated ten times, and an average weight calculated for each of these ten replications, would you expect the ten averages to follow a normal distribution? Are your answers different for (a) and (b)?

Mean of samples and random variables.

The sample mean of n values x_1,\dots,x_n is \m{\bar x = \frac{1}{n}\sum_{i=1}^n x_i = (x_1+x+2+\dots+x_n) / n}

Let X be a random variable that takes possible values x_1,\dots,x_n with probabilities p_1,...,p_n.
The mean of X is also called the \myemph{expected value} of X and is 












\end{myitemize}

\end{document}