%\documentclass[handout]{beamer}
\documentclass{beamer}

\input{../header.tex}
\newcommand\CHAPTER{9}
% \newcommand\answer[2]{\textcolor{blue}{#2}} % to show answers
\newcommand\answer[2]{\textcolor{red}{#2}} % to show answers
% \newcommand\answer[2]{#1} % to show blank space
<<R_answer,echo=F,purl=F>>=
# ANS = TRUE
# ANS=FALSE
@

\begin{document}

% knitr set up
<<knitr_opts,echo=F,cache=F,purl=F>>=
library(knitr)
opts_chunk$set(
#  cache=FALSE,
  cache=TRUE,
  eval=TRUE,
  include=TRUE,
  echo=TRUE,
  purl=TRUE,
  cache.path=paste0("tmp/cache"),
  dev='png',
  dev.args=list(bg='transparent'),
  dpi=300,
  error=FALSE,
  fig.pos="h!",
  fig.align='center',
  fig.height=4,fig.width=6.83,
  fig.lp="fig:",
  fig.path=paste0("tmp/figure"),
  fig.show='asis',
  highlight=TRUE,
  message=FALSE,
  progress=TRUE,
  prompt=FALSE,
#  results='asis',
  results="markup",
  size='small',
  strip.white=TRUE,
  tidy=FALSE,
  warning=FALSE
#  comment=NA # to remove ## on output
)
options(width = 60) # number of characters in R output before wrapping
@

% other set up
<<setup,echo=F,results=F,cache=F>>=
# library(broman) # used for myround 
par(mai=c(0.8,0.8,0.1,0.1))
@


\begin{frame}
\frametitle{\CHAPTER. Additional topics in linear modeling}

\vspace{-2mm}

\myemph{Outline}
\begin{myitemize}
\item We now have practical skills to 
\begin{enumerate}
\item \enumerateSpace
Write down linear models,
\item \enumerateSpace
Fit them in R,
\item \enumerateSpace 
Interpret the output in terms of parameter estimates, confidence intervals and hypothesis tests,
\item \enumerateSpace
Check that R is fitting the model that we intend,
\item \enumerateSpace
Check that the model we intend is appropriate for the data.
\end{enumerate}
\item These skills provide a foundation for many extensions helpful for particuluar situations.
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Topics}

\begin{myitemize}
\item  More on the linear model formula notation in R.
\item Interactions between explanatory variables.
\item The \m{R^2} statistic to assess model fit.
\item  Fitting polynomial relationships using linear models.
\item  Multicollinearity: What happens when two or more explanatory variables are highly correlated. How to notice it, and what to do about it.
\item Power: What is the probability of rejecting the null hypothesis when the alternative is true?
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{The R model formula notation}

\vspace{-2mm}

\begin{myitemize}
\item A \myemph{model formula} in \code{lm()} is something that looks like \code{y~x}.
\item The R formula notation has various conventions that are designed to make it easy to specify useful models.
\item \code{?formula} tells you everything you need to know, and more.
\item You can think of the R formula for \code{lm()} is a way of constructing a design matrix.
\item Inspect the resulting design matrix using \code{model.matrix()} and check you understand what R has produced. If you can do this, you can safely use the power of the formula notation.
\end{myitemize}
\myquestion. In a report, the model should be written in mathematical notation, not as an R formula. Why?

\answer{\vspace{25mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Experimenting with the R formula notation}

\begin{myitemize}
\item Consider the freshman GPA data
<<gpa_data>>=
gpa <- read.table("gpa.txt",header=T); head(gpa,3)
@

\item We can play the game of trying out various things in R formula notation, inspecting the resulting design matrix, and figuring out how to write the model efficiently in mathematical notation.
\item You can also think about whether the different models give any new insights into the data.

\end{myitemize}

\end{frame}

\begin{frame}[fragile]
<<lm_a>>=
lm1 <- lm(GPA~ACT+High_School*Year,data=gpa) 
coef(summary(lm1))[,1:2]
@
\begin{myitemize}
\item The \code{*} here denotes inclusion of an \myemph{interaction} between \code{High_School} and \code{Year}, written in the R output as \code{High_School:Year}.
\end{myitemize}

\vspace{-1mm}

\myquestion. Conceptually, what do you think an interaction between two variables is, and why might it be needed?

\answer{\vspace{15mm}}{todo}

\begin{myitemize}
\item To find out exactly what R thinks an interaction is, we can check the design matrix.
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
<<lm_b>>=
head(model.matrix(lm1))
@

\vspace{-3mm}

\myquestion. Write out the sample model that R has computed in \code{lm1} using subscript notation.

\answer{\vspace{30mm}}{todo}

\end{frame}


\begin{frame}[fragile]
\frametitle{Interactions and additivity}
<<>>=
lm2 <- lm(GPA~ACT+High_School+Year+High_School:Year,data=gpa)
head(model.matrix(lm2),4)
@

\begin{myitemize}
\item \code{lm2} has the same design matrix as \code{lm1}.
\item We see that, in R formula notation, \code{y~u*v} is the same as \code{y~u+v+u:v}.
\item In the model \code{y~u+v} the effects of the variables  are said to be \myemph{additive}. 
\item In a causal interpretation of an additive model, the result of changing \code{u} to \code{u2} and \code{v} to \code{v2} is the sum of the marginal effect of changing \code{u} to \code{u2} plus the marginal effect of changing \code{v} to \code{v2}.
\item The interaction term \code{u:v} breaks additivity. In this case, we can't know the consequence for the fitted value of changing \code{u} to \code{u2} unless we know the value of \code{v}. 
\end{myitemize}

\end{frame}


\begin{frame}[fragile]
\frametitle{The interaction between ACT and high school percentile}

\begin{myitemize}
\item We have not (yet) found any interesting effect of year. Let's drop year out of the model and look for whether there is an interaction between ACT and high school percentile for predicting freshman GPA.
\end{myitemize}
<<>>=
lm3 <- lm(GPA~ACT*High_School,data=gpa)
@
\myquestion. Write out the fitted sample linear model in subscript form, letting \m{y_i}, \m{a_i}, \m{h_i} and \m{e_i} be the freshman GPA, ACT score, high school percentile and residual error respectively for the \m{i}th student.

\answer{\vspace{30mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Interpreting a discovered interaction}

\vspace{-2mm}

<<>>=
coef(summary(lm3))[,1:2]
@

\vspace{-2mm}

\myquestion. Explain in words to the admissions director what you have found about the interaction under investigation here.

\answer{\vspace{35mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Marginal effects when there is an interaction}

\vspace{-2mm}

\begin{myitemize}
\item Notice in `lm3` that the coefficients for ACT score and high school percentile are negative. That is surprising!
\end{myitemize}

\vspace{-2mm}

<<>>=
ACT_centered <- gpa$ACT-mean(gpa$ACT)
HS_centered <- gpa$Hi - mean(gpa$Hi)
lm3b <- lm(GPA~ACT_centered*HS_centered,data=gpa)
signif(coef(summary(lm3b))[,c(1,2,4)],3)
@

\vspace{-3mm}

\myquestion. After centering the variables, the interaction effect stays the same, but the marginal effects change sign. What is happening? Why?

\answer{\vspace{30mm}}{todo}

\end{frame}


\begin{frame}[fragile]
\frametitle{Quantifying the improvement in the model}

\vspace{-2mm} 

<<>>=
s3 <- summary(lm3)$sigma
lm4 <- lm(GPA~ACT+High_School,data=gpa)
s4 <- summary(lm4)$sigma
lm5 <- lm(GPA~1,data=gpa)
s5 <- summary(lm5)$sigma
cat("s3 =",s3,"; s4 =",s4,"; s5 =",s5)
@

\vspace{-2mm} 

\myquestion. Comment on both \myemph{statistical significance} and \myemph{practical significance} of the interaction between  a prediction of freshman GPA.


\answer{\vspace{30mm}}{todo}


\end{frame}



\begin{frame}[fragile]
\frametitle{An interaction involving a factor}

\vspace{-2mm}

\begin{myitemize}
\item Let's go back to the football field goal data. 
\end{myitemize}

\vspace{-2mm} 

<<>>=
<<data>>=
goals <- read.table("FieldGoals2003to2006.csv",header=T,sep=",")
goals[1,c("Name","Teamt","FGt","FGtM1")]
lm6 <- lm(FGt~FGtM1*Name,data=goals)
@

\vspace{-2mm} 

\myquestion. What model do you think is being fitted here? Write it in subscript form, where \m{y_{ij}} is the field goal average for the \m{j}th year of kicker \m{i}, with \m{i=1,\dots,19} and \m{j=1,2,3,4}. Let \m{e_{ij}} be the residual error, and let \m{x_{ij}} be the previous year's average. Check your answer against the design matrix shown on the next slide.

\answer{\vspace{30mm}}{todo}

\end{frame}

\begin{frame}[fragile]

<<>>=
X<-model.matrix(lm6) ; colnames(X)<-1:38 ; X[1:17,c(1:8,21:26)]
@

\end{frame}

\begin{frame}[fragile]
\myquestion. Interpret the ANOVA table below.

\answer{\vspace{25mm}}{todo}

<<>>=
anova(lm6)
@

\end{frame}

\begin{frame}[fragile]
\frametitle{Collinear explanatory variables in a linear model}


\begin{myitemize}
\item Let \m{\mat{X}=[x_{ij}]_{n\times p}} be an \m{n\times p} design matrix. 
\item If there is a nonzero vector \m{\vect{\alpha}=(\alpha_1,\dots,\alpha_p)} such that \m{\mat{X}\vect{\alpha}=\vect{0}} then the columns of \m{\mat{X}} are \myemph{collinear}.
\item Here, \m{\vect{0}} is the zero vector, \m{(0,0,\dots,0)}.
\item We can write \m{\vect{x}_j=(x_{1j},x_{2j},\dots,x_{nj})} for the \m{j}th column of \m{\mat{X}}. Then,
\mydisplaymath{
\mat{X}\vect{\alpha} = \alpha_1\vect{x}_1+\alpha_2\vect{x}_2+\dots+\alpha_j\vect{x}_j.
}
We see that \m{\mat{X}\vect{\alpha}} can be thought of as a \myemph{linear combination of the columns of \m{\mat{X}}}.
\item Collinearity of explanatory variables has important consequences for fitting a linear model to data.
\item It can also be useful to notice whether the variables are close to collinear, meaning that  \m{\mat{X}\vect{\alpha}} is small but nonzero.
\end{myitemize}
\end{frame}

\begin{frame}[fragile]
\frametitle{Example: an intercept with a coefficient for each factor}

\begin{myitemize}
\item Recall the mouse weight dataset. Consider a sample linear model,

\vspace{-2mm}

\mydisplaymath{
y_{ij}=\mu+\mu_j+e_{ij}.
}

\vspace{-2mm}

\item Suppose that we don't set the $\mu_1=0$ so we try to estimate both $\mu_1$ and $\mu_2$ at the same time as the intercept, $\mu$.
\item Let's work with just 3 mice in each treatment group, so \m{i=1,2,3} and \m{j=1,2}. The design matrix is therefore
<<>>=
X <- cbind(rep(1,6),rep(c(1,0),each=3),rep(c(0,1),each=3)) ; X
@
\item For \m{\vect{\alpha}=(1,-1,-1)}, we have \m{\mat{X}\vect{\alpha}=0}
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{The least squares fit with collinear predictors}

\begin{myitemize}
\item Suppose that \m{\vect{b}} is a least squares coefficient vector, so that the fitted value vector \m{\vect{\hat y}=\mat{X}\vect{b}} minimizes \m{\sum_{i=1}^n \big(y_i - \hat y_i\big)^2}.
\item Suppose that \m{\mat{X}} is collinear, with \m{\mat{X}\vect{\alpha}=\vect{0}}.
\item Since
\mydisplaymath{
\mat{X}(\vect{b}+\vect{\alpha}) = \mat{X}\vect{b}+\mat{X}\vect{\alpha} = \mat{X}\vect{b}+\vect{0} = \mat{X}\vect{b},
}
we see that \m{\vect{b}+\vect{\alpha}} is also a least squares coefficient vector.
\item
\myemph{When \m{\mat{X}} is collinear, a least squares coefficent still exists, but it is not unique.}

\end{myitemize}
\myquestion. Let \m{c} be any number. Recall multiplication of a vector by a scalar: \m{c\vect{\alpha}=(c\alpha_1,\dots,c\alpha_p)}. Show that \m{\vect{b}+c \vect{\alpha}} is also a least squares fit.

\vspace{20mm}
\end{frame}

\begin{frame}[fragile]
\frametitle{Standard errors for collinear variables}

\myquestion. Any variable that is part of a collinear combination of variables has infinite standard error. Why?

\answer{\vspace{50mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{What does R do if give it collinear variables?}
<<>>=
mice <- read.table("femaleMiceWeights.csv",header=T,sep=",")
chow=rep(c(1,0),each=12)
hf=rep(c(0,1),each=12)
lm1 <- lm(Bodyweight~chow+hf,data=mice)
coef(summary(lm1))
@

\begin{myitemize}
\item R noticed that the three explanatory variables are collinear, and refused to fit the third
\end{myitemize}
\end{frame}

\begin{frame}[fragile]
<<>>=
model.matrix(lm1)
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Collinear variables and the determinant of $\mat{X}^\transpose\mat{X}$}

\begin{myitemize}
\item Recall that the variance of \m{\hat\beta} in the usual linear model is \m{\sigma^2 \big(\mat{X}^\transpose\mat{X}\big)^{-1}}.
\item Collinearity means the variance is infinite, a matrix version of dividing by zero.
\item Recall that a square matrix is invertible if its determinant is nonzero.
\item We can check that collinearity means \m{\mathrm{det}\big(\mat{X}^\transpose\mat{X}\big)=0}.
<<>>=
X <- model.matrix(lm1)
t(X)%*%X
det(t(X)%*%X)
@
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Linearly independent vectors and matrix rank}

\begin{myitemize}
\item Columns of a matrix that are not collinear are said to be \myemph{linearly independent}.
\item The \myemph{rank} of \m{\mat{X}} is the number of linearly independent columns.
\item \m{\mat{X}} has \myemph{full rank} if all the columns are linearly independent. In this case, we expect the least squares coefficient to be uniquely defined and so \m{\mat{X}^\transpose\mat{X}} has non-zero determinant and is invertible.
\item If \m{\mat{X}} does not have full rank, we can drop \myemph{linearly dependent} columns until the remaining columns are linearly independent. This is a practical approach to handling collinearity.
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Example: reducing a design matrix to full rank}

\vspace{-2mm}

<<>>=
X <- model.matrix(lm1)
det(t(X)%*%X)
X2 <- X[,1:2]
det(t(X2)%*%X2)
@

\vspace{-2mm}

\begin{myitemize}
\item Dropping the third column of \code{X} has given us a full-rank design matrix.
\end{myitemize}
\myquestion. The least squares fitted values are the same using the predictor matrix \code{X2} as \code{X}. Why does dropping the last column not change the fitted values?

\answer{\vspace{20mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Almost collinear variables}

\begin{myitemize}
\item If the determinant of \m{\mat{X}^\transpose\mat{X}} is close to zero, the variance of the model-generated least squares coefficient vector becomes large.
\item This can happen when multiple explanatory variables are included in a model which all model similar things.
\end{myitemize}

\myquestion. Recall our data analysis using unemployment to explain life expectancy. What would happen if we added total employment as an additional explanatory variable? (Being unemployed is not the only alternative to being employed, since only adults currently looking for work are counted as unemployed.)

\answer{\vspace{30mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Using linear models to fit polynomial relationships}

\begin{myitemize}
\item Recall the basic linear trend model from Chapter~1 for data \m{y_1,\dots,y_n} with \m{y_i} measured at time \m{t_i},

\altdisplaymath{
\mathrm{[M1]} \quad y_i = b_0 + b_1 t_i + e_i, \quad i=1,\dots,n
}
\item What if the data have a trend that is not linear?
\item The next thing we might consider is a quadratic trend model,

\altdisplaymath{
\mathrm{[M2]} \quad y_i = b_0 + b_1 t_i + b_2 t_i^2 + e_i, \quad i=1,\dots,n
}
\item M1 and M2 are both linear models, with respective design matrices
\mydisplaymath{
\mat{X}^{[1]}=\begin{bmatrix}
1 & t_1 \\
1 & t_2 \\
\vdots & \vdots \\
1 & t_n
\end{bmatrix}
\quad\quad
\mat{X}^{[2]}=\begin{bmatrix}
1 & t_1 & t_1^2 \\
1 & t_2 & t_2^2 \\
\vdots & \vdots \\
1 & t_n & t_n^2
\end{bmatrix}
}
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{The order $p$ polynomial smoothing model}

\vspace{-2mm}

\begin{myitemize}
\item When the explanatory variable for \m{y_i} is the time of measurement, \m{t_i}, then we call the linear model a trend.
\item When we fit \m{y_i} using a function of an arbitrary explanatory variable $x_i$ we say we are \myemph{smoothing}.
\item We can choose any \m{p} in the general order $p$ polynomial smoothing model,
\end{myitemize}
\altdisplaymath{
\mathrm{[M3]} \quad y_i = b_0 + b_1 x_i + b_2 x_i^2 + b_3 x_i^3 + \dots + b_px_i^p + e_i, \quad i=1,\dots,n
}
\begin{myitemize}
\item This is a linear model with design matrix
\mydisplaymath{
\mat{X}^{[3]}=\begin{bmatrix}
1 & x_1 & x_1^2 & \dots & x_1^p\\
1 & x_2 & x_2^2 & \dots & x_2^p\\
\vdots & \vdots & \vdots & & \vdots \\
1 & x_n & x_n^2 & \dots & x_n^p
\end{bmatrix}
}
\end{myitemize}
\myquestion. How would you decide what order \m{p} to use for the polynomial smoothing?


\answer{\vspace{20mm}}{todo}

\end{frame}

<<reconstruct_variables,echo=F>>=
L <- read.table(file="life_expectancy.txt",header=TRUE)
U <- read.table(file="unemployment.csv",sep=",",header=TRUE)
@

\begin{frame}[fragile]
\frametitle{Cubic polynomial smoothing of life expectancy}

\vspace{-2mm}

<<fit_L_poly3>>=
L_poly3 <- lm(Total~Year+I(Year^2)+I(Year^3),data=L)
@

\begin{columns}[T] 
\begin{column}{0.45\textwidth}
<<fig_L3,eval=F,echo=T>>=
plot(L$Year,L$Total,
  type="line",
  xlab="Year",
  ylab="Life expectancy")
  
lines(L$Year,fitted(L_poly3),
  lty="dashed")
@

\end{column}
\begin{column}{0.45\textwidth}
<<fig_L3_eval,fig.width=5,fig.height=4,out.width="2in",echo=F>>=
par(mai=c(0.8,0.8,0.1,0.1))
<<fig_L3>>
@
\end{column}
\end{columns}

\myquestion. Why do we need to write \code{I(Year^2)} not just \code{Year^2} to fit a polynomial smoothing model in the R formula notation?

\answer{\vspace{20mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Checking the cubic smoothing calculation}
\myquestion. How would you check that the R model formula we wrote is correct for the cubic polynomial we intend to fit?

\answer{\vspace{25mm}}{todo}

\myquestion. If we have done a good job of modeling the trend, we might hope that the residuals look like independent measurement errors. How would you check if this is the case?

\answer{\vspace{25mm}}{todo}

\end{frame}


\begin{frame}[fragile]
\frametitle{Repeating diagnostic tests for life expectancy vs unemployment using cubic detrending}
<<lag_lm>>=
L_detrended <- L_poly3$residuals
U_annual <- apply(U[,2:13],1,mean)
U_detrended <- lm(U_annual~Year+I(Year^2)+I(Year^3),
  data=U)$residuals
L_detrended <- subset(L_detrended,L$Year %in% U$Year)
lm_poly3 <- lm(L_detrended~U_detrended)
n <- length(resid(lm_poly3))
e <- resid(lm_poly3)[2:n] ; lag_e <- resid(lm_poly3)[1:(n-1)]
@

\vspace{-5mm}

\begin{columns}[T] 
\begin{column}{0.45\textwidth}
<<timeplot_code,eval=F,echo=T>>=
plot(U$Year,resid(lm_poly3))
@

\vspace{-14mm}

<<timeplot_plot,fig.width=3,fig.height=3.5,out.width="2in",echo=F>>=
<<timeplot_code>>
@
\end{column}
\begin{column}{0.45\textwidth}
<<lagplot_code,eval=F,echo=T>>=
plot(lag_e,e)
@

\vspace{-14mm}

<<lagplot_plot,fig.width=3,fig.height=3.5,out.width="2in",echo=F>>=
<<lagplot_code>>
@
\end{column}
\end{columns}


\end{frame}

%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Local linear smoothing of life expectancy}

\vspace{-2mm}

<<fit_L_loess>>=
L_loess <- loess(Total~Year,data=L,span=0.3)
@

\begin{columns}[T] 
\begin{column}{0.45\textwidth}
<<fig_L_loess,eval=F,echo=T>>=
plot(L$Year,L$Total,
  type="line",
  xlab="Year",
  ylab="Life expectancy")
  
lines(L$Year,fitted(L_loess),
  lty="dashed",col="red")
@

\end{column}
\begin{column}{0.45\textwidth}
<<fig_L_loess_eval,fig.width=5,fig.height=4,out.width="2in",echo=F>>=
par(mai=c(0.8,0.8,0.1,0.1))
<<fig_L_loess>>
@
\end{column}
\end{columns}

\vspace{-3mm}

\begin{myitemize}
\item \code{loess()} is a \myemph{smoother} that fits a local linear model. This means that, at each point \m{x_j}, the smoother predicts \m{y_i} fitting a linear model that ignores all the data except for points close to \m{x_i}.
\item Setting \code{span=0.3} means that the closest 30\% of the points are used.
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Repeating diagnostic tests for life expectancy vs unemployment using a smoother}
<<lag_loess>>=
L_detrended <- resid(L_loess)
U_annual <- apply(U[,2:13],1,mean)
U_detrended <- resid(loess(U_annual~Year,data=U,span=0.3))
L_detrended <- subset(L_detrended,L$Year %in% U$Year)
lm_loess <- lm(L_detrended~U_detrended)
n <- length(resid(lm_loess))
e <- resid(lm_loess)[2:n] ; lag_e <- resid(lm_loess)[1:(n-1)]
@

\vspace{-5mm}

\begin{columns}[T] 
\begin{column}{0.45\textwidth}
<<timeplot_code_loess,eval=F,echo=T>>=
plot(U$Year,resid(lm_loess))
@

\vspace{-14mm}

<<timeplot_plot_loess,fig.width=3,fig.height=3.5,out.width="2in",echo=F>>=
<<timeplot_code_loess>>
@
\end{column}
\begin{column}{0.45\textwidth}
<<lagplot_code_loess,eval=F,echo=T>>=
plot(lag_e,e)
@

\vspace{-14mm}

<<lagplot_plot_loess,fig.width=3,fig.height=3.5,out.width="2in",echo=F>>=
<<lagplot_code_loess>>
@
\end{column}
\end{columns}


\end{frame}


\begin{frame}[fragile]
\frametitle{Revisiting the evidence for pro-cyclical mortality}
<<>>=
coef(summary(lm_loess))
@

\vspace{-4mm}

\begin{myitemize}
\item Recall that linear detrending gave a signficant association between life expectancy and unemployment.
\item This suggested that mortality is \myemph{pro-cyclical}, meaning it increases when the business cycles is in economic expansion and unemployment is low.
\item In Chapter 7, we found the residuals in this regression had a strong pattern, casting doubt on the validity of our linear model and its unintuitive conclusion.
\end{myitemize}

\vspace{-2mm}

\myquestion. Re-assess the evidence based on this new analysis.

\vspace{20mm}

\end{frame}

\begin{frame}[fragile]
\frametitle{The R-squared statistics to assess goodness of fit}

\begin{myitemize}
\item \m{R^2} is the square of the correlation between the data and the fitted values.
\item It can also be computed as
\mydisplaymath{
R^2 = 1- \frac{\RSS}{\SST} = \frac{\SST-\RSS}{\SST}
}
where \m{\RSS} is the residual sum of squares and \m{\SST} is the total sum of squares, defined as
\mydisplaymath{
\SST = \sum_{i=1}^n \big(y_i-\bar y\big)^2, \quad \mbox{ where } \bar y = \frac{1}{n}\sum_{i=1}^n y_i.
}
\item \m{R^2} is sometimes described as the fraction of the variation in the data explained by the linear model.
\item \m{1-R^2} is the fraction of the variation in the data left unexplained by the model.
\end{myitemize}

\end{frame}


\begin{frame}[fragile]
\frametitle{Uses and abuses of R-squared}

\begin{myitemize}

\item A low \m{R^2} sends a clear signal: the fitted  model doesn't describe the data much better than the sample mean. 

\item Sometimes a small, but statistically significant, correlation is of interest. 
If you are monitoring data on the operation of an aircraft jet engine, you want to know about evidence suggesting a malfunction as soon as it is statistically significant. 
\myemph{Interpretation of R-squared depends on context}. 

\item The \m{R^2} statistic compares the residual sum of squares under the full model with the residual sum of squares under a model with a constant mean. By contrast, the F test compares the full model with a model that omits specific selected explanatory variables. The F test is more appropriate for assessing whether a variable, or group of variables, should be included in the model. 

\end{myitemize}


\end{frame}


\begin{frame}[fragile]
\frametitle{A relationship between the F statistic and R-squared}

\vspace{-2mm}

\begin{myitemize}
\item Recall that in a regression setting, the F statistic is expressed in the following way.
\mydisplaymath{
f=\frac{(\RSS_0-\RSS_a)/d}{\RSS_a/(n-q)}.
}
\item \m{q} is the dimension of the alternative hypothesis.
\item \m{d} is the difference in dimension between the null and alternative hypotheses.
\end{myitemize}

\vspace{-1mm}

\myquestion. Write the hypotheses \m{H_0} and \m{H_a} to match the \m{R^2} statistic in a linear model with \m{p} explanatory variables (including the intercept). Set up these hypotheses so that \m{\RSS_0} is \m{\SST}, and \m{\RSS_a} is \m{RSS}.

\answer{\vspace{20mm}}{todo}


\begin{myitemize}
\item In this context, we see that \m{q=p} and \m{d=p-1}.
\end{myitemize}

\end{frame}


\begin{frame}[fragile]
\frametitle{Writing $R^2$ in terms of an F statistic}

\vspace{-2mm}

\begin{myitemize}
\item From last slide, we have
\mydisplaymath{ 
f=\frac{(\SST-\RSS)/(p-1)}{\RSS/(n-p)}
}
\item Recall that \m{R^2 = 1-\RSS/\SST}. 
\end{myitemize}

\vspace{-3mm}

\myquestion. Check by algebra that
\m{ \displaystyle
R^2=1 - \frac{1}{1+f \times (p-1)/(n-p)}
}

\answer{\vspace{35mm}}{todo}

\myquestion. What is \m{R^2} when \m{F} is very large? or close to zero?

\answer{\vspace{15mm}}{todo}

\end{frame}

\begin{frame}[fragile]

\myquestion. Explain why \m{R^2} cannot decrease when you add an extra explanatory variable into a linear model. (Explanations for questions like this should involve some math notation, not just words.)

\answer{\vspace{45mm}}{todo}

\begin{myitemize}
\item Simplicity in a model is a good thing. The fact that any added model complexity makes \m{R^2} seem ``better'' requires caution in interpretation. 
%\item 
\end{myitemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{Adjusted R-squared}

\vspace{-1.5mm}

\begin{myitemize}
\item One approach to penalize \m{R^2} for a more complex model is to divide each sum of squares by its degrees of freedom. This gives the \myemph{adjusted R-squared},
\mydisplaymath{
R^2_{\mathrm{adj}}=1-\frac{\RSS/(n-p)}{\SST/(n-1)}.
}
\item Dividing by the degrees of freedom in \m{R^2_{\mathrm{adj}}} is like what we do in the F statistic. 
\item The F statistic takes advantage of the nice mathematical property that \m{\SST-\RSS} and \m{\RSS} are independent random variables for the probability model with normally distributed measurement error.
\item For comparing two \myemph{nested} models (when the larger model consists of adding variables to the smaller model) an F test is a clearer statistical argument than comparing \m{R^2_{\mathrm{adj}}}.
\item When the models are not nested, the F test is not applicable. Comparing \m{R^2_{\mathrm{adj}}} values gives one way to assess the models, though not a formal test.

\item  Now we've studied \m{R^2_{\mathrm{adj}}}, we understand everything in \code{summary(lm())}.

\end{myitemize}

\end{frame}


\begin{frame}[fragile]
<<gpa_summary,echo=F>>=
summary(lm(GPA~ACT+High_School,data=gpa))
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Model selection}

\vspace{-1mm}

\begin{myitemize}
\item Suppose we have a large number \m{\ell} of potential explanatory variables in our dataset. 
\item The total number of possible linear models is \m{2^\ell} since each of the \m{\ell} variables can be either in or out of the model.
\item If we allow for the possiblity of interactions, things are even worse. 
\item For two variables \m{x_{i1}} and \m{x_{i2}} on each individual \m{i=1,2,\dots,n}, modeling an \myemph{interaction} can be viewed as including a new variable \m{x_{i3}=x_{i1}x_{i2}}.
\end{myitemize}
\myquestion. If there are \m{\ell} explanatory variables, considered as \myemph{main effects}, and any pair of them could give rise to an \myemph{interaction effect}, how many possible models are there? For simplicity, allow for the possibility of including interactions without the main effects.

\vspace{30mm}

\end{frame}


\begin{frame}[fragile]
\frametitle{Practical considerations for model selection}

%\vspace{-2mm}

\begin{myitemize}
\item Sometimes, you build models based on specific hypotheses about the system you are investigating. 
\item In this case, our tools for hypothesis testing work well. You work through a process of starting with a basic model and considering a relatively small sequence of alternative hypotheses to build up an understanding of the data.
\item A different scenario occurs when you explore a very large number of different models. 
\item If you consider \m{1000} alternative models and each one is tested at significance level \m{0.01} then you expect to find \m{10} models that would formally let you reject the null hypothesis at a ``high'' level of significance for random variables generated under the null model.

\item Similar issues arise if you consider many variables in a single linear model and look to identify significant ones.
\end{myitemize}


\end{frame}

\begin{frame}
\frametitle{The expected number of false discoveries}

\myquestion.  Suppose that you consider \m{\ell=100} variables by placing them all in a linear model and reporting the variables whose t statistic is significant at the \m{0.05} level. How many ``significant'' variables would you expect to report under a null probability model where all the coefficients are zero?

\answer{\vspace{40mm}}{todo}

\end{frame}


\begin{frame}[fragile]
\frametitle{Confidence intervals after model selection}

\myquestion. Suppose you have \m{\ell=100} explanatory variables and you consider \m{\ell=100} different models, each with only one of the explanatory variables in the model. You pick as your favorite model the one with the highest \m{R^2} statistic, which is equivalent to picking the one with the smalles p-value for its t statistic. You report a 95\% confidence interval for the coefficient in this linear model. What is the chance that this confidence interval will cover the truth, under the null probability model where all the coefficients for all the explanatory variables are zero?

\answer{\vspace{40mm}}{todo}

\end{frame}

\begin{frame}[fragile]
\frametitle{Dealing with multiple testing}

\begin{myitemize}
\item The difficulty of properly evaluating statistical significance when investigating very many hypotheses is called the \myemph{multiple testing} situation.
\item Dealing with multiple testing is a current scientific concern. It is related to the so-called crisis in scientific reproducibility.
\item Advances in data acquisition and computation increasingly lead to large datasets to be investigated.
\item One principle: report all the tests you make, not just the nominally significant ones. This lets the reader assess the hazard of multiple testing bias.
\item Another principle: any result not yet confirmed by an independent experiment is suspicious.
\end{myitemize}

\end{frame}


\begin{frame}[fragile]
\frametitle{The causal interpretation of observational studies}

\begin{myitemize}
\item Consider a simple least-squares linear model \m{y_i=ax_i + b +e_i} for \m{i=1,\dots,n}.
The usual corresponding probability model is \m{Y_i=\alpha x_i+\beta +\epsilon_i} with \m{\epsilon_1,\dots,\epsilon_n} being independent \m{N[0,\sigma]} random variables. 

\item The coefficient \m{\alpha} for \m{x_i}, \m{i=1,\dots,n} is commonly called the \myemph{effect} of \m{x_i} on \m{y_i}.
\item Sometimes \m{a} is called the effect, but it is more properly an \myemph{estimated effect}.

\item The \myemph{causal interpretation} of the linear model is that, if we manipulated \m{x_i} to increase it by one unit for individual \m{i}, keeping everything else fixed, we would expect \m{y_i} to increase by \m{a} units.

\item The use of the word ``effect'' has a causal meaning in common usage. 

\item We should think carefully about when this meaning is justified.

\end{myitemize}
\end{frame}



\begin{frame}[fragile]
\frametitle{Does coffee cause heart attacks?}

\begin{myitemize}
\item Coffee has relatively high levels of caffeine, a commonly consumed drug. Many studies have been done to see if it has adverse (or positive) health effects. 
\item A typical observational study will model a health outcome (say, a measure of heart health) and investigate linear models based on available explanatory variables.
\item If higher levels of coffee consumption are associated with lower heart health scores, beyond what can be explained by chance variation in our sample, we will be suspicious about drinking coffee.
\end{myitemize}
\myquestion. Suggest important confounding variable(s) in the causal interpretation of this model. What would you do to help make a convincing argument for or against coffee?

\answer{\vspace{30mm}}{todo}

\end{frame}



\begin{frame}[fragile]
\frametitle{Which surgeon do you choose?}

\begin{myitemize}
\item Cost effectiveness of medical treatment is a major current issue. You are advising a health insurance program, and your boss gives you data on success rates for a certain heart surgery, together with the salary of the surgeon performing the operation. 
\end{myitemize}
\myquestion. Suppose you find the estimated effect is negative and statistically significant: higher salaries are associated with lower success rates. How would you interpret this result? What are possible confounding factors?

\answer{\vspace{40mm}}{todo}


\end{frame}

\begin{frame}[fragile]
  \frametitle{When can we infer causation from observational data?}
The following considerations may add weight to the causal interpretation of an association
\begin{myitemize}
\item There is a plausible mechanism.
\item There are no un-measured variables considered plausible mechanisms.
\item The effect is consistent across population subgroups.
\item For data collected though time, the proposed cause precedes the consequence.
\item Consistency with available experimental evidence.
  \item A consistent gradient between increases in the proposed cause and its consequence. 
\end{myitemize}
The ideas were developed in the 1950s while tracking down the case against cigarettes (Wikipedia: Bradford Hill criteria) and continue to be debated.

\end{frame}


\begin{frame}[fragile]
  \frametitle{How did the observations get into the study?}


\begin{myitemize}
\item  There is risk of \myemph{selection bias} if the individuals are not selected randomly from the population they are supposed to represent.
  \item Selection bias is a type of confounding. The confounder is a variable that explains the selection process.
\end{myitemize}
\myquestion. In World War II, the US Airforce was suffering heavy losses in bombing raids over Germany. To decide where to add extra armor, engineers studied bullet holes on returning planes to see which parts were exposed to most gunfire. A prominent statistician, Abraham Wald, provided a different interpretation. What was it?

\answer{\vspace{30mm}}{todo}

\end{frame}


\begin{frame}[fragile]
\frametitle{Revisiting the fieldgoal kicker data}

\begin{myitemize}
\item Any observations study can and should be examined for confounding and selection bias issues.
\end{myitemize}
\myquestion. Consider the field goal percentage data. Recall that we analyzed the 19 NFL kickers who made at least ten field goal attempts in each of 2002, 2003, 2004, 2005 and 2006 seasons. We found a slope of -0.504 when predicting field goal percentage in year t using field goal percentage in year t-1, with a separate intercept for each kicker. Comment on the possible roles of selection bias and/or confounding for interpreting this result.

\answer{\vspace{30mm}}{todo}

\end{frame}


\begin{frame}[fragile]
\frametitle{Randomized experiments and random samples}

\begin{myitemize}
\item The huge difficulties interpreting observational studies motivate avoiding them whenever possible
\item Random assignment to treatment in a controlled experiment removes the possibility of confounding, and ensures that any statistically significan effect can legitimately be given a causal interpretation.
\item A \myemph{randomized experiment} occurs when individual \m{i} is randomly assigned a \myemph{treatment}. A treatment is a set of explanatory variables corresponding to a row of \m{\mat{X}}.
\item In a randomized experiment the independence assumption on the errors is reasonable: we can view the errors as coming from differences between individuals drawn independently from a large population.
  \item STATS 470 investigates design and analysis of experiments, which is an extension of linear statistical modeling.
  \item Random sampling removes selection bias, apart from missing data.
    \item STATS 480 investigates sample survey analysis, which also builds on linear statistial modeling.
\end{myitemize}

\end{frame}


\end{document}

------- This is just for copying to make new slides ---------

\end{frame}

\begin{frame}[fragile]
\frametitle{}

\begin{myitemize}
\item 
\end{myitemize}

\end{frame}

